# Blog Post Scraper

A reliable, maintainable web scraper that extracts blog posts from various sites with human-like behavior (rate limiting), secure URL validation, and a simple web UI for viewing results.

## Features

- **Web Scraping**: Uses Playwright for JavaScript-heavy sites
- **Pagination Support**: Automatically follows "next page" links
- **Rate Limiting**: 2-5 second delays between requests (human-like behavior)
- **Security**: URL validation to prevent SSRF attacks
- **Web UI**: Simple interface for submitting URLs and viewing results
- **Export**: Download scraped posts as JSON
- **Async Processing**: Support for 3 concurrent scraping jobs

## Tech Stack

- **Backend**: Python 3.11, FastAPI
- **Scraping**: Playwright, BeautifulSoup4, httpx
- **Database**: SQLite with SQLAlchemy ORM
- **Frontend**: HTML/CSS/JavaScript with Bootstrap
- **Testing**: pytest, pytest-benchmark

## Quick Start

### Using Docker (Recommended)

```bash
# Build the image
docker build -t blog-scraper:latest .

# Run the container
docker run -p 8000:8000 blog-scraper:latest

# Access the UI
open http://localhost:8000
```

### Local Development

```bash
# Create virtual environment
python3.11 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Install Playwright browsers
playwright install chromium

# Run the application
uvicorn src.main:app --reload

# Access the UI
open http://localhost:8000
```

## Usage

1. **Submit URL**: Navigate to the home page and enter a blog URL
2. **Monitor Jobs**: Check the "Jobs" page to see scraping progress
3. **View Results**: Browse scraped posts on the "Results" page
4. **Export Data**: Download all posts as JSON

## Configuration

Copy `.env.example` to `.env` and customize:

```bash
# Database
DATABASE_URL=sqlite:///./blog_scraper.db

# Scraping
MAX_PAGES_DEFAULT=10
RATE_LIMIT_MIN=2
RATE_LIMIT_MAX=5

# Server
HOST=0.0.0.0
PORT=8000
```

## Testing

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src tests/

# Run performance benchmarks
pytest tests/test_performance.py --benchmark-only
```

## Project Structure

```
test-blog-scraper/
├── src/
│   ├── scraper/        # Core scraping logic
│   ├── api/            # FastAPI endpoints
│   ├── models/         # Database models
│   ├── static/         # Web UI files
│   ├── config.py       # Configuration
│   ├── database.py     # Database setup
│   └── main.py         # FastAPI app
├── tests/              # Test files
├── requirements.txt    # Python dependencies
├── Dockerfile          # Docker configuration
└── README.md           # This file
```

## API Documentation

Once running, visit:
- Interactive API docs: http://localhost:8000/docs
- Alternative docs: http://localhost:8000/redoc

## Performance Targets

- API response time: <500ms (p95)
- Scraping speed: <5s per page (p95)
- Concurrent jobs: 3 maximum
- Memory usage: <1GB RAM

## Security Features

- URL validation (blocks file://, javascript:, localhost)
- Input sanitization in web UI
- Secure session management
- Rate limiting to prevent IP bans

## Troubleshooting

**Playwright installation fails**:
```bash
playwright install --with-deps chromium
```

**Port 8000 already in use**:
```bash
uvicorn src.main:app --port 8080
```

**Database locked errors**:
- Ensure only one instance is running
- Delete `blog_scraper.db` and restart

## License

MIT

## Generated By

Tech-Lead Agent v1.0 with AI-Driven Development Framework
